{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from constants import *\n",
    "from eda_utils import *\n",
    "from utils import eval_stat\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import math\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Bihar_536_Sensor_Data_Sep_2023_Screened.csv', 'Bihar_536_Sensor_Data_Oct_2023_Screened.csv', 'Bihar_536_Sensor_Data_Nov_2023_Screened.csv',\n",
    "        'Bihar_512_Sensor_Data_May_Aug_Screened_Hourly.csv']\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for f in files:\n",
    "    dataset.append(pd.read_csv(f'{data_bihar}/{f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_to_block = {}\n",
    "lat_long_to_distr = {}\n",
    "\n",
    "for data in dataset:\n",
    "    cols = list(data.columns.values)[1:]\n",
    "\n",
    "    for c in cols:\n",
    "        lat, long = float(data.loc[2, c]), float(data.loc[3, c])\n",
    "\n",
    "        if math.isnan(lat) or math.isnan(long):\n",
    "            continue\n",
    "\n",
    "        if (lat, long) not in lat_long_to_block:\n",
    "            lat_long_to_block[(lat, long)] = data.loc[1, c]\n",
    "            lat_long_to_distr[(lat, long)] = data.loc[0, c]\n",
    "\n",
    "# print(lat_long_to_block)\n",
    "# print(lat_long_to_distr)\n",
    "print(len(lat_long_to_block), len(lat_long_to_distr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping -> (Latitude, Longitude) -> {Timestamp -> ts, Device_ID -> d_id, RH -> rh, Temp -> temp, PM25 -> pm25}\n",
    "full_data = []\n",
    "\n",
    "for data in dataset:\n",
    "    \n",
    "    f_data = {}\n",
    "    # f_data = {'timestamp': [], 'device_id': [], 'block': [], 'district': [], 'latitude': [], 'longitude': [], 'rh': [], \n",
    "    #              'temp': [], 'pm25': []}\n",
    "    \n",
    "    cols = list(data.columns.values)[1:]\n",
    "    ts = list(data.loc[6:, data.columns.values[0]])\n",
    "\n",
    "    for c in cols:\n",
    "        lat, long = float(data.loc[2, c]), float(data.loc[3, c])\n",
    "\n",
    "        if math.isnan(lat) or math.isnan(long):\n",
    "            continue\n",
    "\n",
    "        if (lat, long) not in f_data:\n",
    "            f_data[(lat, long)] = {'timestamp': ts, 'block': lat_long_to_block[(lat, long)], \n",
    "                                   'district': lat_long_to_distr[(lat, long)], 'rh': [], 'temp': [], 'pm25': []}\n",
    "\n",
    "        if c[0] == 'P':                 \n",
    "            # f_data[(lat, long)]['device_id'] = c[5:]            # PM25_ is a 5 length substring\n",
    "            f_data[(lat, long)]['pm25'] = data.loc[6:, c].to_list()\n",
    "        elif c[0] == 'T':\n",
    "            f_data[(lat, long)]['temp'] = data.loc[6:, c].to_list()\n",
    "        elif c[0] == 'R':\n",
    "            f_data[(lat, long)]['rh'] = data.loc[6:, c].to_list()\n",
    "        \n",
    "    full_data.append(f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = {'timestamp': [], 'block': [], 'district': [], 'latitude': [], 'longitude': [], 'rh': [], 'temp': [], 'pm25': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in full_data:\n",
    "\n",
    "    for key in data:\n",
    "        lat, long, sz = key[0], key[1], len(data[key]['timestamp'])\n",
    "        \n",
    "        assert len(data[key]['timestamp']) == len(data[key]['rh']) == len(data[key]['temp']) == len(data[key]['pm25']), \"Improper logic\"\n",
    "\n",
    "        f_data['timestamp'].extend(data[key]['timestamp'])\n",
    "        # f_data['device_id'].extend([data[key]['device_id']] * sz)\n",
    "        f_data['block'].extend([data[key]['block']] * sz)\n",
    "        f_data['district'].extend([data[key]['district']] * sz)\n",
    "        f_data['latitude'].extend([lat] * sz)\n",
    "        f_data['longitude'].extend([long] * sz)\n",
    "        f_data['rh'].extend(data[key]['rh'])\n",
    "        f_data['temp'].extend(data[key]['temp'])\n",
    "        f_data['pm25'].extend(data[key]['pm25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cols = ['timestamp', 'device_id', 'block', 'district', 'latitude', 'longitude', 'rh', 'temp', 'pm25']\n",
    "# df_types = [np.datetime64, object, object, object, float, float, float, float, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=f_data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df = df.dropna(subset=['timestamp', 'pm25'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'{data_bihar}/bihar_512_sensor_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'{data_bihar}/bihar_512_sensor_data_imputed.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = list(df['timestamp'].unique())\n",
    "# unique_dates = sorted(list(set([datetime.strptime(str(ts), \"%Y-%m-%d %H:%M:%S\").date() for ts in times])))\n",
    "# unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['timestamp', 'latitude', 'longitude', 'rh', 'temp', 'pm25']].copy(deep=True)\n",
    "df_new['timestamp'] = df_new['timestamp'].values.astype(float)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_new.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = impute(data, method='iterative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rh'] = imputed_data[:, 3]\n",
    "df['temp'] = imputed_data[:, 4]\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'{data_bihar}/bihar_512_sensor_data_imputed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['random', 'timestamp', 'lat_long']\n",
    "\n",
    "for split in splits:\n",
    "    eval = train_and_eval(imputed_data, method='iterative', model_dir=model_dir, split=split, model_type='xgb')\n",
    "    print(f'{split}: {eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'{data_bihar}/bihar_512_sensor_data_imputed.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(df.groupby(['latitude', 'longitude']).groups.keys())\n",
    "# locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:\n",
      "longitude: 361\n",
      "latitude: 141\n",
      "expver: 2\n",
      "time: 5880\n",
      "['longitude', 'latitude', 'expver', 'time', 'u10', 'v10', 't2m', 'kx', 'sp', 'tp']\n"
     ]
    }
   ],
   "source": [
    "netcdf_file = nc.Dataset(f'{data_bihar}/Era5_data_May_Dec_2023.nc', 'r')\n",
    "pbl_file = nc.Dataset(f'{data_bihar}/PBLH_may_Dec_2023.nc', 'r')\n",
    "\n",
    "\n",
    "dimensions = pbl_file.dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dim_name, dim_obj in dimensions.items():\n",
    "    print(f\"{dim_name}: {len(dim_obj)}\")\n",
    "\n",
    "# Get variables\n",
    "vars = list(netcdf_file.variables.keys())\n",
    "print(vars)\n",
    "# for x in vars:\n",
    "#     if x == 'expver': continue\n",
    "#     print(pbl_file.variables[x].long_name, pbl_file.variables[x].units)\n",
    "\n",
    "# Close the NetCDF file\n",
    "netcdf_file.close()\n",
    "pbl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(netcdf_file.variables.keys())\n",
    "print(pbl_file.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blh = pbl_file.variables['blh'][:]\n",
    "\n",
    "# ts = netcdf_file.variables['longitude'][:]\n",
    "# ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blh[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs776",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
